{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports are good\n",
      "Data gotten, and other global variables initialized\n",
      "Functions have been defined\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unsupervised Learning and Dimensionality Reduction\n",
    "https://gatech.instructure.com/courses/122126/assignments/557954\n",
    "\"\"\"\n",
    "# Verify imports\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "\n",
    "print(\"All imports are good\")\n",
    "\n",
    "# Get the data\n",
    "dataset1 = fetch_openml(name='phoneme') \n",
    "X_ds1 = dataset1.data #matrix\n",
    "y_ds1 = dataset1.target #vector\n",
    "X_Train_ds1, X_Test_ds1, y_Train_ds1, y_Test_ds1 = \\\n",
    "    train_test_split(X_ds1, y_ds1, test_size=0.2, random_state=0) \n",
    "\n",
    "dataset2 = fetch_openml(name='credit-g') \n",
    "X_ds2 = dataset2.data #matrix\n",
    "y_ds2 = dataset2.target #vector\n",
    "X_Train_ds2, X_Test_ds2, y_Train_ds2, y_Test_ds2 = \\\n",
    "    train_test_split(X_ds2, y_ds2, test_size=0.2, random_state=0) \n",
    "\n",
    "# Other global variables:\n",
    "current_dataset = ''\n",
    "\n",
    "print(\"Data gotten, and other global variables initialized\")\n",
    "\n",
    "# Functions\n",
    "\n",
    "def getTime(seconds):\n",
    "    if int(seconds / 60) == 0:\n",
    "        if int(seconds) == 0:\n",
    "            return str(round(seconds,3)) + \" seconds\"\n",
    "        return str(int(seconds)) + pos(int(seconds),\" second\")\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    if int(minutes / 60) == 0:\n",
    "        return str(minutes) + pos(minutes,\" minute\") + \" and \" + str(seconds) + pos(int(seconds),\" second\")\n",
    "    hours = int(minutes / 60)\n",
    "    minutes = int(minutes % 60)\n",
    "    # Assuming this won't be called for any time span greater than 24 hours\n",
    "    return str(hours) + pos(hours,\" hour\") + \", \" + str(minutes) + pos(minutes,\" minute\") \\\n",
    "        + \", and \" + str(seconds) + pos(int(seconds),\" second\")\n",
    "\n",
    "# Plural or singular utility for getTime()\n",
    "def pos(value, unit):\n",
    "    if value == 0 or value > 1:\n",
    "        return unit+\"s\"\n",
    "    return unit\n",
    "\n",
    "# Clustering algorithms\n",
    "def kMeansClustering(X, y):\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "    #https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html\n",
    "    #https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_assumptions.html\n",
    "    #https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html\n",
    "    #https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
    "    pass\n",
    "\n",
    "def expectationMaximization(X, y):\n",
    "    #https://scikit-learn.org/stable/modules/mixture.html#expectation-maximization\n",
    "    #https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\n",
    "    pass\n",
    "\n",
    "# Dimensionality reduction algorithms\n",
    "def PCA(X, y):\n",
    "    #https://scikit-learn.org/stable/modules/decomposition.html#pca\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA\n",
    "    pass\n",
    "\n",
    "def ICA(X, y):\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html\n",
    "    #https://www.oreilly.com/library/view/mastering-machine-learning/9781788621113/753ef7f9-b52e-40aa-8ca3-41c298ea1642.xhtml\n",
    "    pass\n",
    "\n",
    "def randomizedProjections(X, y):\n",
    "    #https://scikit-learn.org/stable/modules/random_projection.html\n",
    "    pass\n",
    "\n",
    "def otherFeatureSelectionAlgorithm(X, y):\n",
    "    #???\n",
    "    pass\n",
    "\n",
    "\n",
    "def neuralNetworks(X, Y, is_debug=False):\n",
    "    mlp = MLPClassifier(solver=solver_ds, alpha=alpha_ds, hidden_layer_sizes=my_hidden_layer, \\\n",
    "        max_iter=y_Train.shape[0], warm_start=True, learning_rate=learning_rate_ds, \\\n",
    "        activation=activation, random_state=0)\n",
    "    #Dataset 1 with best score at hidden layer: (9, 8) with activation = tanh\n",
    "    #alpha order of magnitude: 10.0\n",
    "    #solver: lbfgs\n",
    "    #Dataset 2 with best score at hidden layer: (7, 6) with activation = relu\n",
    "    #alpha order of magnitude: 100.0\n",
    "    #solver: lbfgs\n",
    "    #https://github.gatech.edu/dstrube3/CS7641_A1/blob/master/A1%20-%20Supervised%20Learning%20-%20dstrube3.ipynb\n",
    "\n",
    "print(\"Functions have been defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Run the clustering algorithms on the datasets\n",
    "kMeansClustering(X_Train_ds1, y_Train_ds1)\n",
    "kMeansClustering(X_Train_ds2, y_Train_ds2)\n",
    "expectationMaximization(X_Train_ds1, y_Train_ds1)\n",
    "expectationMaximization(X_Train_ds2, y_Train_ds2)\n",
    "\n",
    "# 2 Apply the dimensionality reduction algorithms to the two datasets\n",
    "X_Train_post_PCA_ds1, y_Train_post_PCA_ds1 = PCA(X_Train_ds1, y_Train_ds1)\n",
    "X_Train_post_ICA_ds1, y_Train_post_ICA_ds1 = ICA(X_Train_ds1, y_Train_ds1)\n",
    "X_Train_post_RPR_ds1, y_Train_post_RPR_ds1 = randomizedProjections(X_Train_ds1, y_Train_ds1)\n",
    "X_Train_post_OFS_ds1, y_Train_post_OFS_ds1 = otherFeatureSelectionAlgorithm(X_Train_ds1, y_Train_ds1)\n",
    "\n",
    "X_Train_post_PCA_ds2, y_Train_post_PCA_ds2 = PCA(X_Train_ds2, y_Train_ds2)\n",
    "X_Train_post_ICA_ds2, y_Train_post_ICA_ds2 = ICA(X_Train_ds2, y_Train_ds2)\n",
    "X_Train_post_RPR_ds2, y_Train_post_RPR_ds2 = randomizedProjections(X_Train_ds2, y_Train_ds2)\n",
    "X_Train_post_OFS_ds2, y_Train_post_OFS_ds2 = otherFeatureSelectionAlgorithm(X_Train_ds2, y_Train_ds2)\n",
    "\n",
    "# 3 Reproduce clustering experiments, but on the data after I've run dimensionality reduction on it. \n",
    "kMeansClustering(X_Train_post_PCA_ds1, y_Train_post_PCA_ds1)\n",
    "kMeansClustering(X_Train_post_PCA_ds2, y_Train_post_PCA_ds2)\n",
    "expectationMaximization(X_Train_post_PCA_ds1, y_Train_post_PCA_ds1)\n",
    "expectationMaximization(X_Train_post_PCA_ds2, y_Train_post_PCA_ds2)\n",
    "\n",
    "kMeansClustering(X_Train_post_ICA_ds1, y_Train_post_ICA_ds1)\n",
    "kMeansClustering(X_Train_post_ICA_ds2, y_Train_post_ICA_ds2)\n",
    "expectationMaximization(X_Train_post_ICA_ds1, y_Train_post_ICA_ds1)\n",
    "expectationMaximization(X_Train_post_ICA_ds2, y_Train_post_ICA_ds2)\n",
    "\n",
    "kMeansClustering(X_Train_post_RPR_ds1, y_Train_post_RPR_ds1)\n",
    "kMeansClustering(X_Train_post_RPR_ds2, y_Train_post_RPR_ds2)\n",
    "expectationMaximization(X_Train_post_RPR_ds1, y_Train_post_RPR_ds1)\n",
    "expectationMaximization(X_Train_post_RPR_ds2, y_Train_post_RPR_ds2)\n",
    "\n",
    "kMeansClustering(X_Train_post_OFS_ds1, y_Train_post_OFS_ds1)\n",
    "kMeansClustering(X_Train_post_OFS_ds2, y_Train_post_OFS_ds2)\n",
    "expectationMaximization(X_Train_post_OFS_ds1, y_Train_post_OFS_ds1)\n",
    "expectationMaximization(X_Train_post_OFS_ds2, y_Train_post_OFS_ds2)\n",
    "\n",
    "# 4 Rerun my neural network learner on the newly projected data.\n",
    "neuralNetworks(X_Train_post_PCA_ds1, y_Train_post_PCA_ds1)\n",
    "neuralNetworks(X_Train_post_PCA_ds2, y_Train_post_PCA_ds2)\n",
    "\n",
    "neuralNetworks(X_Train_post_ICA_ds1, y_Train_post_ICA_ds1)\n",
    "neuralNetworks(X_Train_post_ICA_ds2, y_Train_post_ICA_ds2)\n",
    "\n",
    "neuralNetworks(X_Train_post_RPR_ds1, y_Train_post_RPR_ds1)\n",
    "neuralNetworks(X_Train_post_RPR_ds2, y_Train_post_RPR_ds2)\n",
    "\n",
    "neuralNetworks(X_Train_post_OFS_ds1, y_Train_post_OFS_ds1)\n",
    "neuralNetworks(X_Train_post_OFS_ds2, y_Train_post_OFS_ds2)\n",
    "\n",
    "# 5 Apply the clustering algorithms to the same dataset to which \n",
    "#        I just applied the dimensionality reduction algorithms (already done this), \n",
    "#        treating the clusters as if they were new features. In other words, treat \n",
    "#        the clustering algorithms as if they were dimensionality reduction algorithms. \n",
    "#        Again, rerun your neural network learner on the newly projected data.\n",
    "#???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
